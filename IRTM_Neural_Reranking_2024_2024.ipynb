{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adap7/IRTM/blob/main/IRTM_Neural_Reranking_2024_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkHS4-bywpqG"
      },
      "source": [
        "![Maastricht_University_logo.svg](data:image/svg+xml;base64,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)\n",
        "\n",
        "# Information Retrieval and Text Mining Course - Neural Reranking Tutorial\n",
        "Authors: Abderrahmane Issam and Jan Scholtes\n",
        "\n",
        "Version 2024-2025\n",
        "\n",
        "#Notebook 4\n",
        "\n",
        "In this notebook we will learn how to use [Pyterrier](https://github.com/terrier-org/pyterrier), a Python framework that is built on top of the Java-based Terrier IR platform. Pyterrier can be used to index different formats of datasets and can be integrated with different models starting from classical approaches like BM25 up to neural models like ColBERT. We will learn how to use Pyterrier for indexing, search and evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eq8R0OY6c_U"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k-DRUf1rUfP"
      },
      "source": [
        "### If you have a local GPU (Do the following steps in your local env):\n",
        "If you have a GPU and you want to run this notebook locally, then I suggest you set up a conda environement as follows:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "conda create --name ir python=3.11.1 \\\\\n",
        "conda install -c conda-forge openjdk=11 \\\\\n",
        "pip install notebook\n",
        "```\n",
        "The second step is to start jupyter in your local machine as follows:\n",
        "```\n",
        "jupyter notebook \\\n",
        "    --NotebookApp.allow_origin='https://colab.research.google.com' \\\n",
        "    --port=8888 \\\n",
        "    --NotebookApp.port_retries=0\n",
        "```\n",
        "Then go to `connect to local runtime` (which you will find in the menu where you can change the runtime) and paste the jupter backend URL that tou got in the output of the previous command."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9YW_CKdyp1W"
      },
      "source": [
        "If you are running this locally, then you only need to install packages once, otherwise, you will need to install them at the start of the instance and restart the runtime when required to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOuFzDx1MOnB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1dcbc7b-0a22-4fba-ef97-e581d5e67d53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-terrier\n",
            "  Downloading python_terrier-0.13.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from python-terrier) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from python-terrier) (2.2.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from python-terrier) (10.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from python-terrier) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from python-terrier) (2.32.3)\n",
            "Collecting ir-datasets>=0.3.2 (from python-terrier)\n",
            "  Downloading ir_datasets-0.5.10-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting wget (from python-terrier)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyjnius>=1.4.2 (from python-terrier)\n",
            "  Downloading pyjnius-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from python-terrier) (1.2.18)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from python-terrier) (1.14.1)\n",
            "Collecting ir-measures>=0.3.1 (from python-terrier)\n",
            "  Downloading ir_measures-0.3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pytrec-eval-terrier>=0.5.3 (from python-terrier)\n",
            "  Downloading pytrec_eval_terrier-0.5.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (984 bytes)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from python-terrier) (3.1.6)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from python-terrier) (0.14.4)\n",
            "Collecting dill (from python-terrier)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from python-terrier) (1.4.2)\n",
            "Collecting chest (from python-terrier)\n",
            "  Downloading chest-0.2.3.tar.gz (9.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lz4 (from python-terrier)\n",
            "  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier) (4.13.3)\n",
            "Collecting inscriptis>=2.2.0 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading inscriptis-2.6.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier) (5.3.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier) (6.0.2)\n",
            "Collecting trec-car-tools>=2.5.4 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\n",
            "Collecting warc3-wet>=0.2.3 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zlib-state>=0.1.3 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting ijson>=3.1.3 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting unlzw3>=0.2.1 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: pyarrow>=16.1.0 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier) (18.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->python-terrier) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->python-terrier) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->python-terrier) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->python-terrier) (2025.1.31)\n",
            "Collecting heapdict (from chest->python-terrier)\n",
            "  Downloading HeapDict-1.0.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->python-terrier) (1.17.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->python-terrier) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->python-terrier) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->python-terrier) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->python-terrier) (2025.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->python-terrier) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels->python-terrier) (24.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier) (4.13.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->python-terrier) (1.17.0)\n",
            "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading python_terrier-0.13.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.4/163.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ir_datasets-0.5.10-py3-none-any.whl (859 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.0/859.0 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ir_measures-0.3.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyjnius-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytrec_eval_terrier-0.5.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.0/288.0 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.2/119.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inscriptis-2.6.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
            "Downloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\n",
            "Downloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\n",
            "Downloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
            "Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
            "Building wheels for collected packages: chest, wget, warc3-wet-clueweb09, cbor\n",
            "  Building wheel for chest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chest: filename=chest-0.2.3-py3-none-any.whl size=7611 sha256=322987cd7e986ab6fed40352de8aa4affb1c7441aa6dca41dc2ae26fa37b41cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/57/13/28831e81239278141f874ee9b7d6d5490a1b1191c2d07a3e73\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=ec1b9fb438c1a93e0ec57194e8084f0ac1eb45c88628ef5e9a3e9ff44086896e\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18919 sha256=a52db1bf4075cf47844c4fc245c2ac6e685830f2056cf84f0a36ae9a4878e8ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/f9/dc/2dd16d3330e327236e4d407941975c42d5159d200cdb7922d8\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cbor: filename=cbor-1.0.0-cp311-cp311-linux_x86_64.whl size=53930 sha256=d5cfd4c6220ec1aa3ba3fdc7aff116c5f23aa5c2ecf8b4a5dae159dc60edc777\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/6b/45/0c34253b1af07d1d9dc524f6d44d74a6b191c43152e6aaf641\n",
            "Successfully built chest wget warc3-wet-clueweb09 cbor\n",
            "Installing collected packages: wget, warc3-wet-clueweb09, warc3-wet, pyjnius, ijson, heapdict, cbor, zlib-state, unlzw3, trec-car-tools, pytrec-eval-terrier, lz4, dill, chest, ir-measures, inscriptis, ir-datasets, python-terrier\n",
            "Successfully installed cbor-1.0.0 chest-0.2.3 dill-0.3.9 heapdict-1.0.1 ijson-3.3.0 inscriptis-2.6.0 ir-datasets-0.5.10 ir-measures-0.3.7 lz4-4.4.4 pyjnius-1.6.1 python-terrier-0.13.0 pytrec-eval-terrier-0.5.7 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 wget-3.2 zlib-state-0.1.9\n"
          ]
        }
      ],
      "source": [
        "!pip install python-terrier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKWUw0s5uQLc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f924546-fe50-44ce-d207-47a348fd4649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/terrierteam/pyterrier_colbert.git\n",
            "  Cloning https://github.com/terrierteam/pyterrier_colbert.git to /tmp/pip-req-build-regzso_x\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/terrierteam/pyterrier_colbert.git /tmp/pip-req-build-regzso_x\n",
            "  Resolved https://github.com/terrierteam/pyterrier_colbert.git to commit ba5c86c0bc8da450dee361140541f35b5349a492\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT (from pyterrier-colbert==0.0.1)\n",
            "  Cloning https://github.com/cmacdonald/ColBERT.git (to revision v0.2) to /tmp/pip-install-ir022m0e/colbert_16bab09840e74a40bbf8ad5815517de8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cmacdonald/ColBERT.git /tmp/pip-install-ir022m0e/colbert_16bab09840e74a40bbf8ad5815517de8\n",
            "  Running command git checkout -b v0.2 --track origin/v0.2\n",
            "  Switched to a new branch 'v0.2'\n",
            "  Branch 'v0.2' set up to track remote branch 'v0.2' from 'origin'.\n",
            "  Resolved https://github.com/cmacdonald/ColBERT.git to commit ec191156d9c18f9f057103d3f2c9576c3eba2595\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-terrier>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from pyterrier-colbert==0.0.1) (0.13.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pyterrier-colbert==0.0.1) (2.2.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pyterrier-colbert==0.0.1) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pyterrier-colbert==0.0.1) (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (2.0.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (10.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (2.32.3)\n",
            "Requirement already satisfied: ir-datasets>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (0.5.10)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.11/dist-packages (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (3.2)\n",
            "Requirement already satisfied: pyjnius>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (1.6.1)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (1.2.18)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (1.14.1)\n",
            "Requirement already satisfied: ir-measures>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (0.3.7)\n",
            "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in /usr/local/lib/python3.11/dist-packages (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (0.5.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (3.1.6)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (0.14.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (0.3.9)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (1.4.2)\n",
            "Requirement already satisfied: chest in /usr/local/lib/python3.11/dist-packages (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (0.2.3)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.11/dist-packages (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (4.4.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pyterrier-colbert==0.0.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pyterrier-colbert==0.0.1) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pyterrier-colbert==0.0.1) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pyterrier-colbert==0.0.1) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.6.0->pyterrier-colbert==0.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.6.0->pyterrier-colbert==0.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.6.0->pyterrier-colbert==0.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.6.0->pyterrier-colbert==0.0.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.6.0->pyterrier-colbert==0.0.1)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.6.0->pyterrier-colbert==0.0.1)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.6.0->pyterrier-colbert==0.0.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.6.0->pyterrier-colbert==0.0.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.6.0->pyterrier-colbert==0.0.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pyterrier-colbert==0.0.1) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pyterrier-colbert==0.0.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pyterrier-colbert==0.0.1) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.6.0->pyterrier-colbert==0.0.1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pyterrier-colbert==0.0.1) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pyterrier-colbert==0.0.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->pyterrier-colbert==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: transformers<5,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (4.50.3)\n",
            "Collecting ujson (from ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Collecting mlflow<=2.5 (from ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading mlflow-2.5.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (2.18.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pyterrier-colbert==0.0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pyterrier-colbert==0.0.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pyterrier-colbert==0.0.1) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyterrier-colbert==0.0.1) (3.6.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (4.13.3)\n",
            "Requirement already satisfied: inscriptis>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (2.6.0)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (5.3.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (6.0.2)\n",
            "Requirement already satisfied: trec-car-tools>=2.5.4 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (2.6)\n",
            "Requirement already satisfied: warc3-wet>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (0.2.5)\n",
            "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (0.2.5)\n",
            "Requirement already satisfied: zlib-state>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (0.1.9)\n",
            "Requirement already satisfied: ijson>=3.1.3 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (3.3.0)\n",
            "Requirement already satisfied: unlzw3>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (0.2.3)\n",
            "Requirement already satisfied: pyarrow>=16.1.0 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (18.1.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (8.1.8)\n",
            "Collecting cloudpickle<3 (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting databricks-cli<1,>=0.8.7 (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading databricks_cli-0.18.0-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.11/dist-packages (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (0.4)\n",
            "Requirement already satisfied: gitpython<4,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (3.1.44)\n",
            "Collecting protobuf<5,>=3.12.0 (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting pytz>=2020.1 (from pandas->pyterrier-colbert==0.0.1)\n",
            "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting packaging<24 (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting importlib-metadata!=4.7.0,<7,>=3.7.0 (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (0.5.3)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting docker<7,>=4.0.0 (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading docker-6.1.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting Flask<3 (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading flask-2.3.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting numpy (from python-terrier>=0.9.1->pyterrier-colbert==0.0.1)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting querystring-parser<2 (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl.metadata (559 bytes)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (2.0.40)\n",
            "INFO: pip is looking at multiple versions of mlflow to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mlflow<=2.5 (from ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading mlflow-2.4.2-py3-none-any.whl.metadata (12 kB)\n",
            "  Downloading mlflow-2.4.1-py3-none-any.whl.metadata (12 kB)\n",
            "  Downloading mlflow-2.4.0-py3-none-any.whl.metadata (12 kB)\n",
            "  Downloading mlflow-2.3.2-py3-none-any.whl.metadata (12 kB)\n",
            "  Downloading mlflow-2.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "  Downloading mlflow-2.3.0-py3-none-any.whl.metadata (12 kB)\n",
            "  Downloading mlflow-2.2.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->pyterrier-colbert==0.0.1)\n",
            "  Downloading pytz-2022.7.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "INFO: pip is still looking at multiple versions of mlflow to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mlflow<=2.5 (from ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading mlflow-2.2.1-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading mlflow-2.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading mlflow-2.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting importlib-metadata!=4.7.0,<6,>=3.7.0 (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading importlib_metadata-5.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (3.10.0)\n",
            "Collecting packaging<23 (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading packaging-22.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting pandas (from pyterrier-colbert==0.0.1)\n",
            "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting mlflow<=2.5 (from ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading mlflow-2.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting sqlalchemy<2,>=1.4.0 (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading SQLAlchemy-1.4.54-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting mlflow<=2.5 (from ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading mlflow-2.0.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting packaging<22 (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading packaging-21.3-py3-none-any.whl.metadata (15 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting mlflow<=2.5 (from ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading mlflow-1.30.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting prometheus-flask-exporter<1 (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading prometheus_flask_exporter-0.23.2-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting gunicorn<21 (from mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1)\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pyterrier-colbert==0.0.1) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (2025.1.31)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=3.0.2->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (0.30.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=3.0.2->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=3.0.2->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=3.0.2->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (0.5.3)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.11/dist-packages (from chest->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (1.17.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (3.0.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (1.71.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (3.1.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (1.1.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (2.6)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from databricks-cli<1,>=0.8.7->mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (2.10.1)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from databricks-cli<1,>=0.8.7->mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from databricks-cli<1,>=0.8.7->mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (0.9.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from docker<7,>=4.0.0->mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (1.8.0)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3->mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3->mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (1.9.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=2.1.0->mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (4.0.12)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata!=4.7.0,<6,>=3.7.0->mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (3.21.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from packaging<22->mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (3.2.3)\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.11/dist-packages (from prometheus-flask-exporter<1->mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (0.21.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<2,>=1.4.0->mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (3.1.1)\n",
            "Requirement already satisfied: cbor>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier>=0.9.1->pyterrier-colbert==0.0.1) (1.0.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow<=2.5->ColBERT@ git+https://github.com/cmacdonald/ColBERT.git@v0.2#egg=ColBERT->pyterrier-colbert==0.0.1) (5.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow-1.30.1-py3-none-any.whl (17.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Downloading databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask-2.3.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.1/96.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
            "Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prometheus_flask_exporter-0.23.2-py3-none-any.whl (19 kB)\n",
            "Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Downloading SQLAlchemy-1.4.54-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyterrier-colbert, ColBERT\n",
            "  Building wheel for pyterrier-colbert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyterrier-colbert: filename=pyterrier_colbert-0.0.1-py3-none-any.whl size=26095 sha256=f4ae5932c505f18e85d2c3c90eba6c12df69604f51afeb41b086c35d095455a6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-657ivkd6/wheels/f1/17/b8/a5438ff50fc5af20593c6b56cf729b350a4e97a02c445b338d\n",
            "  Building wheel for ColBERT (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ColBERT: filename=ColBERT-0.2.0-py3-none-any.whl size=48644 sha256=3028581e054509e6b3954b04a1412807966e59bb2af65f9f726240fd29989f32\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-657ivkd6/wheels/14/0d/8c/45b6f0bd80ebe138bbe08197041c6a434eb8cae3a0be2d5c50\n",
            "Successfully built pyterrier-colbert ColBERT\n",
            "Installing collected packages: pytz, ujson, sqlalchemy, querystring-parser, protobuf, packaging, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, importlib-metadata, gunicorn, cloudpickle, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, Flask, docker, databricks-cli, alembic, prometheus-flask-exporter, nvidia-cusolver-cu12, mlflow, ColBERT, pyterrier-colbert\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.40\n",
            "    Uninstalling SQLAlchemy-2.0.40:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.40\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.1\n",
            "    Uninstalling cloudpickle-3.1.1:\n",
            "      Successfully uninstalled cloudpickle-3.1.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: Flask\n",
            "    Found existing installation: Flask 3.1.0\n",
            "    Uninstalling Flask-3.1.0:\n",
            "      Successfully uninstalled Flask-3.1.0\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.54 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "pandas-gbq 0.28.0 requires packaging>=22.0.0, but you have packaging 21.3 which is incompatible.\n",
            "langsmith 0.3.24 requires packaging>=23.2, but you have packaging 21.3 which is incompatible.\n",
            "dask 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
            "distributed 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "mizani 0.13.2 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\n",
            "opentelemetry-api 1.31.1 requires importlib-metadata<8.7.0,>=6.0, but you have importlib-metadata 5.2.0 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2025.1.2 requires packaging>=23.2, but you have packaging 21.3 which is incompatible.\n",
            "xarray 2025.1.2 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "sphinx 8.2.3 requires packaging>=23.0, but you have packaging 21.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "langchain-core 0.3.51 requires packaging<25,>=23.2, but you have packaging 21.3 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "astropy 7.0.1 requires packaging>=22.0.0, but you have packaging 21.3 which is incompatible.\n",
            "google-cloud-bigquery 3.31.0 requires packaging>=24.2.0, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ColBERT-0.2.0 Flask-2.3.3 alembic-1.15.2 cloudpickle-2.2.1 databricks-cli-0.18.0 docker-6.1.3 gunicorn-20.1.0 importlib-metadata-5.2.0 mlflow-1.30.1 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 packaging-21.3 pandas-1.5.3 prometheus-flask-exporter-0.23.2 protobuf-4.25.6 pyterrier-colbert-0.0.1 pytz-2022.7.1 querystring-parser-1.2.4 sqlalchemy-1.4.54 ujson-5.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata",
                  "packaging"
                ]
              },
              "id": "29f5e1d91ab64008901336ed6a997909"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade git+https://github.com/terrierteam/pyterrier_colbert.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnZel0gn6klB"
      },
      "source": [
        "## Indexing and Search Using Pyterrier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOulTM8FuZ6G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb72cf42-31bb-4f16-ad6e-d0610c6b9b9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu-cu12\n",
            "  Downloading faiss_gpu_cu12-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu12) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu12) (21.3)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu12) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu12) (12.4.5.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from packaging->faiss-gpu-cu12) (3.2.3)\n",
            "Downloading faiss_gpu_cu12-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu-cu12\n",
            "Successfully installed faiss-gpu-cu12-1.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-gpu-cu12\n",
        "\n",
        "import faiss\n",
        "assert faiss.get_num_gpus() > 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XdkLDajxhxl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716fab8d-71a8-4b8a-8e09-bada7baf2542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "terrier-assemblies 5.11 jar-with-dependencies not found, downloading to /root/.pyterrier...\n",
            "Done\n",
            "terrier-python-helper 0.0.8 jar not found, downloading to /root/.pyterrier...\n",
            "Done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Java started and loaded: pyterrier.java, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n",
            "<ipython-input-2-10f47eda998d>:3: DeprecationWarning: Call to deprecated method pt.init(). Deprecated since version 0.11.0.\n",
            "java is now started automatically with default settings. To force initialisation early, run:\n",
            "pt.java.init() # optional, forces java initialisation\n",
            "  pt.init()\n"
          ]
        }
      ],
      "source": [
        "import pyterrier as pt\n",
        "if not pt.java.started():\n",
        "    pt.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5BAIBa03bvQ"
      },
      "source": [
        "Pyterrier can create an index from different dataset formats including Pandas DataFrame which we demonstrate below. We will create a synthetic DataFrame of documents, as well as queries and qrels to use for evaluation. After indexing the documents, we create a BM25 model that we will use for search later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7p66B8Vj05j1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d8a29b-899c-4be2-daa9-3cade78a7604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove './index': No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-83e90585fa44>:29: DeprecationWarning: Call to deprecated class DFIndexer. (use pt.terrier.IterDictIndexer().index(dataframe.to_dict(orient='records')) instead) -- Deprecated since version 0.11.0.\n",
            "  indexer = pt.index.DFIndexer(index_path)\n",
            "<ipython-input-3-83e90585fa44>:33: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n",
            "  bm25 = pt.BatchRetrieve(index_ref, wmodel=\"BM25\")\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Define Documents\n",
        "documents = pd.DataFrame([\n",
        "    {\"docno\": \"d1\", \"text\": \"PyTerrier is great for information retrieval.\"},\n",
        "    {\"docno\": \"d2\", \"text\": \"Terrier is a powerful information retrieval platform.\"},\n",
        "    {\"docno\": \"d3\", \"text\": \"Python is a popular programming language.\"},\n",
        "    {\"docno\": \"d4\", \"text\": \"This tutorial introduces PyTerrier basics.\"}\n",
        "])\n",
        "\n",
        "# 2. Define Queries\n",
        "queries = pd.DataFrame([\n",
        "    {\"query\": \"information retrieval\", \"qid\": \"q1\"},\n",
        "    {\"query\": \"programming tutorial\", \"qid\": \"q2\"}\n",
        "])\n",
        "\n",
        "# 3. Define Relevance Judgments (qrels)\n",
        "qrels = pd.DataFrame([\n",
        "    {\"qid\": \"q1\", \"docno\": \"d1\", \"label\": 1},\n",
        "    {\"qid\": \"q1\", \"docno\": \"d2\", \"label\": 0},\n",
        "    {\"qid\": \"q2\", \"docno\": \"d3\", \"label\": 1},\n",
        "    {\"qid\": \"q2\", \"docno\": \"d4\", \"label\": 1}\n",
        "])\n",
        "\n",
        "# 4. Indexing\n",
        "index_path = \"./index\"\n",
        "!rm -r \"./index\"    # Remove index if it exists\n",
        "\n",
        "indexer = pt.index.DFIndexer(index_path)\n",
        "index_ref = indexer.index(text=documents[\"text\"], docno=documents[\"docno\"])\n",
        "\n",
        "# 5. Retrieval (BM25)\n",
        "bm25 = pt.BatchRetrieve(index_ref, wmodel=\"BM25\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eUhSsVi41bR"
      },
      "source": [
        "We can see the files were created:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59FwuzR74zSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "917b1c6d-21ee-4838-c674-4503ad83cd4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 44K\n",
            "-rw-r--r-- 1 root root    7 Apr 11 11:35 data.direct.bf\n",
            "-rw-r--r-- 1 root root   64 Apr 11 11:35 data.meta.zdata\n",
            "-rw-r--r-- 1 root root   32 Apr 11 11:35 data.meta.idx\n",
            "-rw-r--r-- 1 root root   68 Apr 11 11:35 data.document.fsarrayfile\n",
            "-rw-r--r-- 1 root root   44 Apr 11 11:35 data.meta-0.fsomapfile\n",
            "-rw-r--r-- 1 root root    9 Apr 11 11:35 data.inverted.bf\n",
            "-rw-r--r-- 1 root root 1.1K Apr 11 11:35 data.lexicon.fsomapfile\n",
            "-rw-r--r-- 1 root root   52 Apr 11 11:35 data.lexicon.fsomapid\n",
            "-rw-r--r-- 1 root root  321 Apr 11 11:35 data.lexicon.fsomaphash\n",
            "-rw-r--r-- 1 root root 4.1K Apr 11 11:35 data.properties\n"
          ]
        }
      ],
      "source": [
        "!ls -ltrh ./index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z9m-HZC5eqm"
      },
      "source": [
        "We can see statistics of our index as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IHuEfHo5W0Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c938f6-ad25-42ca-a823-72b38d74ca39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 4\n",
            "Number of terms: 13\n",
            "Number of postings: 15\n",
            "Number of fields: 0\n",
            "Number of tokens: 15\n",
            "Field names: []\n",
            "Positions:   false\n",
            "\n"
          ]
        }
      ],
      "source": [
        "index = pt.IndexFactory.of(index_ref)\n",
        "print(index.getCollectionStatistics().toString())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "terms = index.getLexicon()\n",
        "\n",
        "for entry in terms:\n",
        "    print(entry.getKey())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpaKb2HAy2wF",
        "outputId": "67420cbf-a73d-4f85-fd12-cd46356203dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "basic\n",
            "great\n",
            "introduc\n",
            "languag\n",
            "platform\n",
            "popular\n",
            "power\n",
            "program\n",
            "pyterri\n",
            "python\n",
            "retriev\n",
            "terrier\n",
            "tutori\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdPHTupu7L7D"
      },
      "source": [
        "### Exercise 1:\n",
        "The number of terms (13) is less than the number of words in all the 4 documents. Explain the reason for this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drITzeUS7o_4"
      },
      "source": [
        "I printed the 13 terms to check them and to see that they re unique terms (after pre processing).\n",
        "\n",
        "This can happen because we have a total of 13 terms, but actually 15 tokens because some tokens (the rest of 2) are terms that repeat in more than one document, so they are not unique terms, but 15 tokens in all docs.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh9NRiq17rUI"
      },
      "source": [
        "These are the terms identified by Pyterrier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnVLk2eb52Yj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe1c3a2-d00b-4ad3-f7e8-92993df38a9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "basic -> term11 Nt=1 TF=1 maxTF=1 @{0 0 0}\n",
            "great -> term2 Nt=1 TF=1 maxTF=1 @{0 0 6}\n",
            "introduc -> term12 Nt=1 TF=1 maxTF=1 @{0 1 0}\n",
            "languag -> term6 Nt=1 TF=1 maxTF=1 @{0 1 6}\n",
            "platform -> term4 Nt=1 TF=1 maxTF=1 @{0 2 2}\n",
            "popular -> term8 Nt=1 TF=1 maxTF=1 @{0 2 6}\n",
            "power -> term3 Nt=1 TF=1 maxTF=1 @{0 3 2}\n",
            "program -> term9 Nt=1 TF=1 maxTF=1 @{0 3 6}\n",
            "pyterri -> term1 Nt=2 TF=2 maxTF=1 @{0 4 2}\n",
            "python -> term7 Nt=1 TF=1 maxTF=1 @{0 5 0}\n",
            "retriev -> term0 Nt=2 TF=2 maxTF=1 @{0 5 4}\n",
            "terrier -> term5 Nt=1 TF=1 maxTF=1 @{0 6 0}\n",
            "tutori -> term10 Nt=1 TF=1 maxTF=1 @{0 6 4}\n"
          ]
        }
      ],
      "source": [
        "for kv in index.getLexicon():\n",
        "  print(\"%s -> %s\" % (kv.getKey(), kv.getValue().toString() ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjDLGnUD3KGc"
      },
      "source": [
        "We can search a Pyterrier index using BM25 with the following function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luy2PLR41pIF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "b8c66e12-af47-4ac4-f68f-d987d8e1759e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  qid  docid docno  rank     score                 query\n",
              "0   1      2    d3     0  2.379879  programming language"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa6ad68d-d608-4d96-93d6-ea146c46de08\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "      <th>docno</th>\n",
              "      <th>rank</th>\n",
              "      <th>score</th>\n",
              "      <th>query</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>d3</td>\n",
              "      <td>0</td>\n",
              "      <td>2.379879</td>\n",
              "      <td>programming language</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa6ad68d-d608-4d96-93d6-ea146c46de08')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fa6ad68d-d608-4d96-93d6-ea146c46de08 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fa6ad68d-d608-4d96-93d6-ea146c46de08');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"bm25\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"qid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"docid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"docno\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"d3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rank\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 2.3798790503895453,\n        \"max\": 2.3798790503895453,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2.3798790503895453\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"programming language\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "bm25.search(\"programming language\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rwMqoQc6H-n"
      },
      "source": [
        "\n",
        "### Exercise2\n",
        "\n",
        "Define each column in the output of search above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNLKkTrP6emc"
      },
      "source": [
        "Write answer here:\n",
        "\n",
        "- qid: the id of each query we defined\n",
        "- docid: each odcument is getting assigned an ID for the computer during indexing so this is what it will use.\n",
        "- docno: the actual document number we defined in the beggning\n",
        "- rank: this shows the rank of the document so basically in this case doc3 was ranked first for this query (and has the higest score). we could show this for all 4 docs.\n",
        "- score: this is the score we have for the most relevant document related to our query. We want a higher score which means the doc is more relevant.\n",
        "- query: this is the text querry that we search in our documents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLTBNBtL2ODV"
      },
      "source": [
        "Pyterrier offers a way to evaluate models using a different metrics. The list of possible metrics to use is available here: https://pyterrier.readthedocs.io/en/latest/experiments.html#evaluation-measures-objects. \\\\\n",
        "\n",
        "We can also see how `Experiment` accepts a DataFrame of queries and qrels which are used to compute the metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUATv90115EO"
      },
      "outputs": [],
      "source": [
        "# 6. Evaluation Pipeline\n",
        "pt.Experiment([bm25], queries, qrels, eval_metrics=[\"map\", \"P_10\"], names=[\"BM25\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJeWweJI0Ae-"
      },
      "source": [
        "### Exercise 3\n",
        "\n",
        "Instead of BM25 use a TF_IDF model. Try using it to search for a query then pass it along with bm25 to `Experiment`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xceGNabM0qwM"
      },
      "outputs": [],
      "source": [
        "# Write answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckaiDTg43C_g"
      },
      "source": [
        "## Neural Reranking with ColBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuGjM_kV3ZG1"
      },
      "source": [
        "Below we use `pyterrier_colbert` which is a plugin for Pyterrier that makes it possible to use a ColBERT model for indexing and retrieval. We will use the [Vaswani NPL corpus](http://ir.dcs.gla.ac.uk/resources/test_collections/npl/), a corpus of 11,429 scientific abstract, with corresponding queries and relevance assessments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3piECYQzyr2M"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./colbertindex\n",
        "\n",
        "import pyterrier_colbert.indexing\n",
        "\n",
        "checkpoint=\"http://www.dcs.gla.ac.uk/~craigm/colbert.dnn.zip\"\n",
        "\n",
        "indexer = pyterrier_colbert.indexing.ColBERTIndexer(checkpoint, \"./\", \"colbertindex\", chunksize=3)\n",
        "indexer.index(pt.get_dataset(\"irds:vaswani\").get_corpus_iter())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AH2uGTZrytcY"
      },
      "outputs": [],
      "source": [
        "!ls -ltrh ./colbertindex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4Icwt63850or"
      },
      "outputs": [],
      "source": [
        "pyterrier_colbert_factory = indexer.ranking_factory()\n",
        "\n",
        "colbert_e2e = pyterrier_colbert_factory.end_to_end()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybry5guU4fdb"
      },
      "source": [
        "We search using ColBERT as follows. `% 5` is used to retrieve the top 5 most relevant entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cUHiew777u-p"
      },
      "outputs": [],
      "source": [
        "out = (colbert_e2e % 5).search(\"chemical reactions\")\n",
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ke0EQqSeAB8y"
      },
      "outputs": [],
      "source": [
        "out.loc[0, 'query_toks']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YLfKWXDwAXxg"
      },
      "outputs": [],
      "source": [
        "out.loc[0, 'query_embs'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Ik7N5I486-"
      },
      "source": [
        "### Exercise 4\n",
        "\n",
        "There are two new columns in the search results: `query_toks` and `query_embs`. Explain what they are and explain the shape of `query_embs`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPwbuljc5PIp"
      },
      "source": [
        "Write answer here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ItyOEk1371Qt"
      },
      "outputs": [],
      "source": [
        "dataset = pt.datasets.get_dataset(\"vaswani\")\n",
        "index_path = \"./index\"\n",
        "\n",
        "\n",
        "!rm -rf ./index\n",
        "indexer = pt.TRECCollectionIndexer(index_path)\n",
        "\n",
        "indexer = indexer.index(dataset.get_corpus())\n",
        "\n",
        "bm25 = pt.BatchRetrieve(indexer, wmodel=\"BM25\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2sMaSOnC3oE"
      },
      "source": [
        "In the following code we create a sentence transformer reranker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Uz3nxtVIt0DY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import CrossEncoder\n",
        "crossmodel = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2', max_length=512)\n",
        "\n",
        "def _crossencoder_apply(df : pd.DataFrame):\n",
        "  return crossmodel.predict(list(zip(df['query'].values, df['text'].values)))\n",
        "\n",
        "cross_encT = pt.apply.doc_score(_crossencoder_apply, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTnCYtUmDCeH"
      },
      "source": [
        "We create a reranking pipeline that starts with BM25 as a retriever, and ends with using a sentence transformer (cross_encT) for reranking the retrieved documents. The reranking step requires the document text as input, which is not returned by default by bm25, and that is why we add `pt.text.get_text(dataset, 'text')` to retrieve the text documents and add them to the output of BM25."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PLn1pcbguEFE"
      },
      "outputs": [],
      "source": [
        "dataset = pt.get_dataset('irds:vaswani')\n",
        "cross_enc_rerank = bm25 >> pt.text.get_text(dataset, 'text') >> cross_encT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vgYHDbpLym97"
      },
      "outputs": [],
      "source": [
        "out = (bm25 % 5).search(\"chemical reactions\")\n",
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ggpLB8xsuLfi"
      },
      "outputs": [],
      "source": [
        "out = (cross_enc_rerank % 5).search(\"chemical reactions\")\n",
        "out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHJZpudmGoBf"
      },
      "source": [
        "The following demonstrates how we can contruct IR pipelines using Pyterrier. The pipeline starts by using bm25 to retrive relevant documents, which are then used by QueryExpantion transformer which expands the query by adding informative terms that are collected from the relevant documents. The last part runs bm25 with the new query. This process is called Pseudo Relevance Feedback (PRF)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DzvolexLGTvT"
      },
      "outputs": [],
      "source": [
        "query_expansion = bm25 >> pt.rewrite.QueryExpansion(indexer) >> bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "na2LRG7D6DmV"
      },
      "outputs": [],
      "source": [
        "pt.Experiment(\n",
        "    [bm25, query_expansion, colbert_e2e, cross_enc_rerank],\n",
        "    dataset.get_topics(),\n",
        "    dataset.get_qrels(),\n",
        "    eval_metrics=[\"map\", \"P_10\", \"mrt\"],\n",
        "    names = [\"BM25\", \"QE\", \"ColBERT\", \"BM25 >> CrossEnc\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prA5VNDsnyZo"
      },
      "source": [
        "On this small dataset, we can see that BM25 achieves better results than ColBERT. Adding Query Expansion improves MAP a little. But using PRF with ColBERT hurts (ColBERT-PRF) the performance while slowing down the inference because of the extra PRF step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK5XC3ZRD0bT"
      },
      "source": [
        "### Exercise 5\n",
        "\n",
        "Apply the same process as above on a dataset of your choice. You can find the list of datasets in Pyterrier here: https://pyterrier.readthedocs.io/en/latest/datasets.html#available-datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH4cZR2uESN_"
      },
      "source": [
        "### Exercise 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjfgZfphEU5h"
      },
      "source": [
        "Add at least 2 other metrics and explain what each of them is trying to capture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "noiY-9XlEQi1"
      },
      "outputs": [],
      "source": [
        "# Answer both exercise 5 and 6 here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5lUPUg0FVr1"
      },
      "source": [
        "### Exercise 7\n",
        "\n",
        "Follow the example in this [README](https://github.com/terrierteam/pyterrier_colbert/tree/ba5c86c0bc8da450dee361140541f35b5349a492) to implement Pseudo Relevance Feedback (PRF) with ColBERT. Describe how it works, and add ColBERT-PRF to `Experiment` to evaluate it against the other pipelines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohH4C-aA2nbL"
      },
      "source": [
        "Write answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6imuGA8j3EF5"
      },
      "source": [
        "### Exercise 8\n",
        "\n",
        "Implement a reranking pipeline with ColBERT and add it to `Experiment`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etg8FnL03QO3"
      },
      "source": [
        "Write answer here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKg5xc4M7qCr"
      },
      "source": [
        "## Arxiv Abstracts Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "t7YoCn027zTU"
      },
      "outputs": [],
      "source": [
        "!pip install setuptools==68.0.0       # you ca skip this if you are using a local instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EZA0145agJz3"
      },
      "outputs": [],
      "source": [
        "!pip install arxiv==2.1.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjYatix_7-jB"
      },
      "source": [
        "The following code will retrive 1000 abstracts for the query \"nlp\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FhHd1nCoAcw6"
      },
      "outputs": [],
      "source": [
        "import arxiv\n",
        "\n",
        "# Search for papers\n",
        "search = arxiv.Search(\n",
        "    query=\"nlp\",\n",
        "    max_results=1000,\n",
        "    sort_by=arxiv.SortCriterion.SubmittedDate\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msizIv3r8F07"
      },
      "source": [
        "We construct a dictionary of titles and abstracts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM2bzkxDBQo1"
      },
      "outputs": [],
      "source": [
        "documents = []\n",
        "for result in search.results():\n",
        "    documents.append({\n",
        "        'title': result.title,\n",
        "        'abstract': result.summary,\n",
        "\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoj8xG1WuILx"
      },
      "outputs": [],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwkvkQmZHUb5"
      },
      "source": [
        "Rerun this in case you had to restart the session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkdP7YURHTZQ"
      },
      "outputs": [],
      "source": [
        "import pyterrier as pt\n",
        "if not pt.java.started():\n",
        "    pt.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z56iqtvA8LaD"
      },
      "source": [
        "To create an index, we need to to have a docno field which we create below, and a text field which is the abstract in this case. \\\\\n",
        "We use `DFIndexer` which allows us to create by passing a list ids and text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmIiaGl3CXWY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "index_path = './arxivindex'\n",
        "!rm -r './arxivindex'\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'docno': ['doc'+str(i) for i in range(len(documents))],\n",
        "    'text': [document['abstract'] for document in documents]\n",
        "})\n",
        "\n",
        "indexer = pt.DFIndexer(index_path)\n",
        "indexer.index(docno=df.docno, text=df.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKoVc-Uq870G"
      },
      "source": [
        "We create a BM25 retrieval model for the Arxiv index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLlwtIQMvIQN"
      },
      "outputs": [],
      "source": [
        "bm25 = pt.BatchRetrieve(indexer, wmodel=\"BM25\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JKd8SP69LaZ"
      },
      "outputs": [],
      "source": [
        "(bm25 % 5).search(\"information retrieval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rv220WiL4dm9"
      },
      "outputs": [],
      "source": [
        "df[df['docno']=='doc670'].text.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQGIdbrBvoXd"
      },
      "source": [
        "### Exercise 9\n",
        "\n",
        "Create a ColBERT index using the Arxiv documents retrieved above and use it to search for some queries. Try to highlight how it is different from BM25 through the query results. You can also change the query we used to get arxiv pages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jr2lJcMf7k3w"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}