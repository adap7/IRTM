{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adap7/IRTM/blob/main/Copy_of_02_4_IRTM_Tutorial_reranking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start by copying this into your Google Drive!!"
      ],
      "metadata": {
        "id": "wuI8asb82hyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Information Retrieval & Text Mining 2023\n",
        "![maastricht-university-logo.jpeg](data:image/jpeg;base64,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)\n",
        "## Tutorial 2 - Notebook 4"
      ],
      "metadata": {
        "id": "gJDQYAkH2i9l"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXr3PQyEK8N8"
      },
      "source": [
        "In this notebook, we will finetune and evaluate BERT for re-ranking on [MS MACRO](https://huggingface.co/datasets/ms_marco) dataset. We will be using HuggingFace to finetune the model, which makes it easy to plug in any pretrained model on HF Hub that can be used for sequence classification. The model will be finetuned to output a score between 0 and 1 when given a pair of query and passage. You can check the [original paper](https://arxiv.org/abs/1901.04085) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1Y7Xmh2awV0"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrCw-Et-c4Gl"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, load_dataset\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoTokenizer\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_bE5zUNNw6z"
      },
      "source": [
        "We start by loading the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0gr9HLNbs8b"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset('ms_marco', 'v1.1')\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otT6bFhxN42u"
      },
      "source": [
        "We convert the each set to a Pandas DataFrame to make it easier to handle the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkPuJw5Bc8ro"
      },
      "outputs": [],
      "source": [
        "original_train_df = dataset['train'].to_pandas()\n",
        "original_validation_df = dataset['validation'].to_pandas()\n",
        "original_test_df = dataset['test'].to_pandas()\n",
        "\n",
        "len(original_train_df), len(original_validation_df), len(original_test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-dbvnMAkN9w"
      },
      "outputs": [],
      "source": [
        "original_validation_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSn2nOaIOYIN"
      },
      "source": [
        "We sample 10% of each set because training on the whole dataset will take a lot of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCeBUK-G45WU"
      },
      "outputs": [],
      "source": [
        "train_df = original_train_df.sample(frac=0.1).reset_index(drop=True)\n",
        "validation_df = original_validation_df.sample(frac=0.1).reset_index(drop=True)\n",
        "test_df = original_test_df.sample(frac=0.1).reset_index(drop=True)\n",
        "\n",
        "len(train_df), len(validation_df), len(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmNHJQImOqXg"
      },
      "source": [
        "If you check passages column, you can see it contains a dictionary with keys and values. We will split that dictionary into multiple columns with keys as the column names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vq5V9Nzj6Z4"
      },
      "outputs": [],
      "source": [
        "train_df = pd.concat([train_df, pd.json_normalize(train_df['passages'])], axis=1)\n",
        "validation_df = pd.concat([validation_df, pd.json_normalize(validation_df['passages'])], axis=1)\n",
        "test_df = pd.concat([test_df, pd.json_normalize(test_df['passages'])], axis=1)\n",
        "\n",
        "validation_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENRFCxAJPOID"
      },
      "source": [
        "We want our model to take 1 query and 1 `passage_text` and predict the label `is_selected`. We get closer to the format expected by the model by running explode on `is_selected` and `passage_text` columns to get 1 item per row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXlOWynspjfI"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.explode(['is_selected', 'passage_text', 'url'])\n",
        "validation_df = validation_df.explode(['is_selected', 'passage_text', 'url'])\n",
        "test_df = test_df.explode(['is_selected', 'passage_text', 'url'])\n",
        "\n",
        "validation_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8AIzqphplFT"
      },
      "outputs": [],
      "source": [
        "len(train_df), len(validation_df), len(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKgNBfcJSbmf"
      },
      "source": [
        "Below we use [distilbert-base-uncased](https://huggingface.co/distilbert-base-uncased) as it is smaller and faster. The model is expected to take a query and a passage and predict a probability of the passage being relevant. by passing 1 to `num_labels`, HuggingFace will add a linear layer with 1 single output, and that is what we need to get our probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBd9qKLqiel8"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgV0hRNXT6YT"
      },
      "source": [
        "After passing a list of queries and passages to the tokenizer, it will automatically concatenate them and put a \\[SEP] token in between."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ik3I_dn6m_26"
      },
      "outputs": [],
      "source": [
        "out = tokenizer([\"query\"], [\"passage\"])\n",
        "decoded_out = tokenizer.decode(out['input_ids'][0])\n",
        "\n",
        "print(f\"Model input: {out}\")\n",
        "print(f\"Model input decoded: {decoded_out}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FeAn2FaVtgt"
      },
      "source": [
        "The model takes a tokenized pair and output one logit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2QJbdtki2PQ"
      },
      "outputs": [],
      "source": [
        "model(**tokenizer([\"query\"], [\"document\"], return_tensors='pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMi99uD-sEn4"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.rename(columns={'is_selected': 'labels'})\n",
        "validation_df = validation_df.rename(columns={'is_selected': 'labels'})\n",
        "test_df = test_df.rename(columns={'is_selected': 'labels'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oqXmEvuqQ__"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
        "validation_dataset = Dataset.from_pandas(validation_df, preserve_index=False)\n",
        "test_dataset = Dataset.from_pandas(test_df, preserve_index=False)\n",
        "\n",
        "validation_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcx6-SaQqPHk"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"query\"], examples[\"passage_text\"], truncation=True, padding=True)\n",
        "\n",
        "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_validation_dataset = validation_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "tokenized_validation_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KgcCrCPXRTB"
      },
      "source": [
        "We need to customize the trainer to compute binary cross entropy loss. We turn logits into probabilities by applying sigmoid function, then we compute our loss.\n",
        "\n",
        "### Exercise #1\n",
        "Update the code below to use [nn.BCEWithLogitsLoss()](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html) instead of nn.BCELoss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oEDT0EIfqTM"
      },
      "outputs": [],
      "source": [
        "class BCELossTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\").to(torch.float32)\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss_fct = nn.BCELoss()\n",
        "        sigmoid = nn.Sigmoid()\n",
        "        probs = sigmoid(logits)\n",
        "        loss = loss_fct(probs.view(-1), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated code ex 1:\n",
        "class BCELossTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\").to(torch.float32)\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss_fct = nn.BCEWithLogitsLoss()\n",
        "        loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "TfgEtlR36V3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZmSQcqzagui"
      },
      "source": [
        "We clone the [original paper implementation repository](https://github.com/nyu-dl/dl4marco-bert) to be able to use the metrics they defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsmeHO3EvrZf"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "!test -d bert_repo || git clone https://github.com/maryszmary/dl4marco-bert dl4marco-bert\n",
        "if not 'dl4marco-bert' in sys.path:\n",
        "  sys.path += ['dl4marco-bert']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ2b_W4ScRDu"
      },
      "source": [
        "We format labels and scores as expected by metrics. We need to pass a set of ground truth document ids (in this case it's indices where label is larger than 1) and ordered document ids from most relevant to least that we order based on the scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTrFblRfxyfh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import metrics\n",
        "\n",
        "METRICS_MAP = ['MAP', 'RPrec', 'NDCG', 'MRR', 'MRR@10']\n",
        "\n",
        "labels = np.array([1, 0, 0])\n",
        "scores = np.array([0.1, 0.8, 0.3])\n",
        "\n",
        "gt = set(list(np.where(labels > 0)[0]))\n",
        "pred_docs = scores.argsort()[::-1]\n",
        "\n",
        "results = metrics.metrics(gt=gt, pred=pred_docs, metrics_map=METRICS_MAP)\n",
        "\n",
        "print(f\"Ground Truth: {gt}\")\n",
        "print(f\"Predicted docs: {pred_docs}\")\n",
        "print(f\"Results: {results}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYpZj83LjyKN"
      },
      "source": [
        "To compute metrics, we need a list of labels and predictions for each query instead of the exploded version that we prepared before to train the model. That is why we group by `query_ids`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LD_zpSBYFkC"
      },
      "outputs": [],
      "source": [
        "def prepare_compute_metrics(query_ids):\n",
        "  def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.squeeze()\n",
        "    df = pd.DataFrame.from_dict({'labels': labels, 'preds': preds, 'query_ids': query_ids})\n",
        "    df = df.groupby('query_ids').agg(list)\n",
        "\n",
        "    df['labels'] = df['labels'].map(lambda x: set(list(np.where(np.array(x) > 0)[0])))\n",
        "    df['preds'] = df['preds'].map(lambda x: np.array(x).argsort()[::-1])\n",
        "\n",
        "    all_metrics = np.zeros(len(METRICS_MAP))\n",
        "    for _, row in df.iterrows():\n",
        "      all_metrics+=metrics.metrics(row['labels'], row['preds'], metrics_map=METRICS_MAP)\n",
        "\n",
        "    all_metrics/=len(df)\n",
        "\n",
        "    return {\n",
        "        metric: result for metric, result in zip(METRICS_MAP, all_metrics)\n",
        "    }\n",
        "\n",
        "  return compute_metrics\n",
        "\n",
        "query_ids = tokenized_validation_dataset['query_id']\n",
        "compute_metrics = prepare_compute_metrics(query_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rOS_W-7hahz"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"bert_reranker\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0eRFW-qs6Ui"
      },
      "outputs": [],
      "source": [
        "trainer = BCELossTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_validation_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjbgFa0Blh17"
      },
      "source": [
        "### Exercise #2\n",
        "Write code to get metric results of the model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy9RidIzl9wx"
      },
      "outputs": [],
      "source": [
        "# Prepare the metrics function for the test set using query_ids from the tokenized test dataset.\n",
        "test_query_ids = tokenized_test_dataset['query_id']\n",
        "compute_metrics_test = prepare_compute_metrics(test_query_ids)\n",
        "\n",
        "# Instantiate a trainer for evaluation on the test dataset.\n",
        "# (You can reuse training arguments; these will be used for evaluation as well.)\n",
        "test_trainer = BCELossTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    eval_dataset=tokenized_test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics_test\n",
        ")\n",
        "\n",
        "# Run evaluation on the test set and collect the results.\n",
        "test_results = test_trainer.evaluate()\n",
        "\n",
        "# Print the computed metric results for the test set.\n",
        "print(\"Test Set Metric Results:\")\n",
        "print(test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSdRc6WyrUJb"
      },
      "source": [
        "###Exercise #3\n",
        "Save the model, then load it back and use it to predict scores for the lists of queries and passages below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4M9jujvnRfa"
      },
      "outputs": [],
      "source": [
        "queries = original_validation_df.loc[0:5, 'query'].tolist()\n",
        "passages = original_validation_df.loc[0:5, 'passages'].tolist()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# ---------------------------\n",
        "# Step 1: Save the model and tokenizer\n",
        "# ---------------------------\n",
        "# Save the current model and tokenizer after training\n",
        "save_directory = \"saved_model\"\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(f\"Model and tokenizer saved to '{save_directory}'.\")\n",
        "\n",
        "# ---------------------------\n",
        "# Step 2: Load the model and tokenizer back\n",
        "# ---------------------------\n",
        "loaded_model = AutoModelForSequenceClassification.from_pretrained(save_directory)\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
        "\n",
        "print(\"Model and tokenizer loaded successfully.\")\n",
        "\n",
        "# ---------------------------\n",
        "# Step 3: Define lists of queries and passages for prediction\n",
        "# ---------------------------\n",
        "# Replace these sample entries with your own queries and passages as needed\n",
        "queries = [\n",
        "    \"Where can I watch football?\",\n",
        "    \"What are the latest developments in science?\",\n",
        "    \"How do I fix my car?\"\n",
        "]\n",
        "\n",
        "passages = [\n",
        "    \"Football games are broadcasted on many channels across the country.\",\n",
        "    \"Recent scientific breakthroughs have been announced in the field of renewable energy.\",\n",
        "    \"Fixing a car may involve replacing worn-out parts or performing a simple tune-up.\"\n",
        "]\n",
        "\n",
        "# ---------------------------\n",
        "# Step 4: Tokenize the input pairs\n",
        "# ---------------------------\n",
        "inputs = loaded_tokenizer(\n",
        "    queries,\n",
        "    passages,\n",
        "    return_tensors=\"pt\",  # Return PyTorch tensors\n",
        "    truncation=True,\n",
        "    padding=True\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# Step 5: Generate predictions\n",
        "# ---------------------------\n",
        "# Disable gradient calculation for inference\n",
        "with torch.no_grad():\n",
        "    outputs = loaded_model(**inputs)\n",
        "    # For models with num_labels=1, logits is expected to have shape [batch_size, 1]\n",
        "    # We'll squeeze it into a 1D tensor for easier interpretation.\n",
        "    scores = outputs.logits.squeeze(dim=-1)\n",
        "\n",
        "# ---------------------------\n",
        "# Step 6: Display the predicted scores\n",
        "# ---------------------------\n",
        "print(\"Predicted scores:\")\n",
        "for query, score in zip(queries, scores.tolist()):\n",
        "    print(f\"Query: '{query}'  Score: {score:.4f}\")"
      ],
      "metadata": {
        "id": "1p9IU_oqwHxo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}